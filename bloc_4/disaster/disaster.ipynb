{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet - Real or Not? NLP with Disaster Tweets\n",
    "\n",
    "## Project description \n",
    "\n",
    "* Competition - https://www.kaggle.com/c/nlp-getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground base related import\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "# Import Tensorflow & Pathlib librairies\n",
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, GRU, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basics statistics: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7552</td>\n",
       "      <td>5080</td>\n",
       "      <td>7613</td>\n",
       "      <td>7613.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>221</td>\n",
       "      <td>3341</td>\n",
       "      <td>7503</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>USA</td>\n",
       "      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>104</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     keyword location  \\\n",
       "count    7613.000000        7552     5080   \n",
       "unique           NaN         221     3341   \n",
       "top              NaN  fatalities      USA   \n",
       "freq             NaN          45      104   \n",
       "mean     5441.934848         NaN      NaN   \n",
       "std      3137.116090         NaN      NaN   \n",
       "min         1.000000         NaN      NaN   \n",
       "25%      2734.000000         NaN      NaN   \n",
       "50%      5408.000000         NaN      NaN   \n",
       "75%      8146.000000         NaN      NaN   \n",
       "max     10873.000000         NaN      NaN   \n",
       "\n",
       "                                                     text      target  \n",
       "count                                                7613  7613.00000  \n",
       "unique                                               7503         NaN  \n",
       "top     11-Year-Old Boy Charged With Manslaughter of T...         NaN  \n",
       "freq                                                   10         NaN  \n",
       "mean                                                  NaN     0.42966  \n",
       "std                                                   NaN     0.49506  \n",
       "min                                                   NaN     0.00000  \n",
       "25%                                                   NaN     0.00000  \n",
       "50%                                                   NaN     0.00000  \n",
       "75%                                                   NaN     1.00000  \n",
       "max                                                   NaN     1.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id           0.000000\n",
       "keyword      0.801261\n",
       "location    33.272035\n",
       "text         0.000000\n",
       "target       0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####\n",
    "# Load & Explore\n",
    "# ######\n",
    "import pandas as pd \n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "print(\"Basics statistics: \")\n",
    "data_desc = data.describe(include='all')\n",
    "display(data_desc)\n",
    "\n",
    "print(\"Percentage of missing values: \")\n",
    "display(100*data.isnull().sum()/data.shape[0])\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# English pipeline optimized for CPU. \n",
    "# Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.\n",
    "###########\n",
    "!python -m spacy download en_core_web_md -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spacy and english \n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Import Stop words \n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    57.034021\n",
       "1    42.965979\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# let's take only text & target\n",
    "##############\n",
    "data = data[['text', 'target']]\n",
    "\n",
    "# let' take a look a the baseline\n",
    "(data['target'].value_counts()/data.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          text_clean  \n",
       "0               deed reason earthquake allah forgive  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident ask shelter place notify officer evac...  \n",
       "3  13000 people receive wildfire evacuation order...  \n",
       "4  got send photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####\n",
    "## Cleanup the text\n",
    "###########\n",
    "\n",
    "# remove none alphanum & single space characters\n",
    "data[\"text_clean\"] = data[\"text\"].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \"))\n",
    "\n",
    "# remove spaces\n",
    "data[\"text_clean\"] = data[\"text_clean\"].apply(lambda x: x.replace(\" +\",\" \").lower().strip())\n",
    "\n",
    "# remove stopword (“a”, “the”, “is”, “are” and etc) & lemmatization (play, played, player, playing --> play)\n",
    "data[\"text_clean\"] = data[\"text_clean\"].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x) if (token.lemma_ not in STOP_WORDS) and (token.text not in STOP_WORDS)]))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[3657, 414, 169, 1380, 1937]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[119, 3, 158, 511, 5544, 5545, 1087]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[1381, 444, 1703, 324, 5546, 290, 183, 1703, 3...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "      <td>[2308, 7, 2309, 69, 183, 311, 36]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[199, 175, 122, 5547, 1704, 184, 69, 2310, 110]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "      <td>rockyfire update   california hwy 20 close dir...</td>\n",
       "      <td>[2311, 166, 36, 1260, 445, 312, 841, 789, 280,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood disaster heavy rain cause flash flooding...</td>\n",
       "      <td>[24, 17, 633, 155, 49, 634, 490, 381, 5548, 79...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "      <td>m hill fire wood</td>\n",
       "      <td>[2, 1088, 3, 1705]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "      <td>s emergency evacuation happen building street</td>\n",
       "      <td>[5, 16, 183, 176, 32, 381]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "      <td>m afraid tornado come area</td>\n",
       "      <td>[2, 1938, 281, 13, 205]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "5  #RockyFire Update => California Hwy. 20 closed...       1   \n",
       "6  #flood #disaster Heavy rain causes flash flood...       1   \n",
       "7  I'm on top of the hill and I can see a fire in...       1   \n",
       "8  There's an emergency evacuation happening now ...       1   \n",
       "9  I'm afraid that the tornado is coming to our a...       1   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3  13000 people receive wildfire evacuation order...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "5  rockyfire update   california hwy 20 close dir...   \n",
       "6  flood disaster heavy rain cause flash flooding...   \n",
       "7                                   m hill fire wood   \n",
       "8      s emergency evacuation happen building street   \n",
       "9                         m afraid tornado come area   \n",
       "\n",
       "                                        text_encoded  text_len  \n",
       "0                       [3657, 414, 169, 1380, 1937]         5  \n",
       "1               [119, 3, 158, 511, 5544, 5545, 1087]         7  \n",
       "2  [1381, 444, 1703, 324, 5546, 290, 183, 1703, 3...        11  \n",
       "3                  [2308, 7, 2309, 69, 183, 311, 36]         7  \n",
       "4    [199, 175, 122, 5547, 1704, 184, 69, 2310, 110]         9  \n",
       "5  [2311, 166, 36, 1260, 445, 312, 841, 789, 280,...        12  \n",
       "6  [24, 17, 633, 155, 49, 634, 490, 381, 5548, 79...        12  \n",
       "7                                 [2, 1088, 3, 1705]         4  \n",
       "8                         [5, 16, 183, 176, 32, 381]         6  \n",
       "9                            [2, 1938, 281, 13, 205]         5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "## Instanciate the tokenizer & tokenize the cleaned text\n",
    "###########\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=15000)  # instanciate the tokenizer\n",
    "tokenizer.fit_on_texts(data.text_clean)\n",
    "\n",
    "data[\"text_encoded\"] = tokenizer.texts_to_sequences(data.text_clean)\n",
    "data[\"text_len\"] = data[\"text_encoded\"].apply(lambda x: len(x))\n",
    "data = data[data[\"text_len\"] != 0]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is perfectly normal, Tensorflow is incapable as of now to create a tensor dataset based on lists, \n",
    "# we will have to store all of our encoded texts into a single numpy array before creating the tensorflow dataset.\n",
    "# The problem is that not all our sequences are the same length, this is where the `tf.keras.preprocessing.sequence.pad_sequences` \n",
    "# comes in handy, it will add zero padding at the beginning (`padding=\"pre\"`) or at the end (`padding=\"post\"`) of your sequences so they all have equal length.\n",
    "text_pad = tf.keras.preprocessing.sequence.pad_sequences(data.text_encoded, padding=\"post\")\n",
    "full_ds = tf.data.Dataset.from_tensor_slices((text_pad, data.target.values))\n",
    "\n",
    "# Train Test Split\n",
    "n_samples = data.shape[0]\n",
    "TAKE_SIZE = int(0.7 * n_samples) # (split 70%/30%)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "shuffled_ds = full_ds.shuffle(n_samples, reshuffle_each_iteration=False)\n",
    "train_ds = shuffled_ds.take(TAKE_SIZE).shuffle(TAKE_SIZE).batch(BATCH_SIZE)\n",
    "val_ds = shuffled_ds.skip(TAKE_SIZE).shuffle(n_samples - TAKE_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:51:39.699326: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-01-27 10:51:39.699341: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-01-27 10:51:39.699577: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:51:40.024673: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/42 [=>............................] - ETA: 1s - loss: 2.0981 - accuracy: 0.5078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:51:40.348950: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-01-27 10:51:40.348966: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-01-27 10:51:40.410828: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-01-27 10:51:40.411505: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-01-27 10:51:40.412180: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40\n",
      "\n",
      "2022-01-27 10:51:40.412813: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40/AFYves-2.local.trace.json.gz\n",
      "2022-01-27 10:51:40.413372: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40\n",
      "\n",
      "2022-01-27 10:51:40.413517: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40/AFYves-2.local.memory_profile.json.gz\n",
      "2022-01-27 10:51:40.413826: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40\n",
      "Dumped tool data for xplane.pb to /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40/AFYves-2.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40/AFYves-2.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40/AFYves-2.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40/AFYves-2.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /Users/ycammarata/.keras/logs/embedding/train/plugins/profile/2022_01_27_10_51_40/AFYves-2.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 1.9153 - accuracy: 0.5682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:51:41.434038: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 32ms/step - loss: 1.9153 - accuracy: 0.5682 - val_loss: 1.7140 - val_accuracy: 0.5585\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 1.5425 - accuracy: 0.6039 - val_loss: 1.3724 - val_accuracy: 0.5800\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 1.2289 - accuracy: 0.6359 - val_loss: 1.0941 - val_accuracy: 0.6063\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.9807 - accuracy: 0.6581 - val_loss: 0.8867 - val_accuracy: 0.6046\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.8064 - accuracy: 0.6656 - val_loss: 0.7566 - val_accuracy: 0.6111\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.7054 - accuracy: 0.6919 - val_loss: 0.6883 - val_accuracy: 0.6743\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.6524 - accuracy: 0.7647 - val_loss: 0.6583 - val_accuracy: 0.7786\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.6055 - accuracy: 0.8239 - val_loss: 0.6234 - val_accuracy: 0.7856\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.5508 - accuracy: 0.8553 - val_loss: 0.5924 - val_accuracy: 0.7913\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.4990 - accuracy: 0.8716 - val_loss: 0.5754 - val_accuracy: 0.7979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3cd69a220>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################\n",
    "## Setup the model\n",
    "###################\n",
    "\n",
    "# use a 64 values vector to represent a word\n",
    "embedding_dim = 64 \n",
    "vocab_size = 15000 # len(tokenizer.word_counts) + 1\n",
    "imput_shape = text_pad.shape[1]\n",
    "log_dir_base = \"/Users/ycammarata/.keras/logs/\"\n",
    "\n",
    "# Let's create a learning rate schedule to decrease the learning rate as we train the model. \n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir_base+'embedding')\n",
    "\n",
    "DROPOUT = 0.40 # %40\n",
    "\n",
    "### Simple model, one embding later\n",
    "model_emb = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_shape=[imput_shape,], name=\"embedding\"), # the embedding layer\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation='relu', kernel_regularizer='l1'), # a dense layer\n",
    "    Dense(8, activation='relu'), # a dense layer\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(1, activation=\"sigmoid\") # the prediction layer\n",
    "])\n",
    "\n",
    "model_emb.compile(\n",
    "    optimizer=Adam(learning_rate = lr_schedule), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_emb.fit(train_ds, epochs=10, validation_data=val_ds, callbacks=[tensorboard_callback, earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:49:40.562200: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-01-27 10:49:40.562214: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-01-27 10:49:40.562383: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-01-27 10:49:43.325322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:49:45.013184: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/42 [>.............................] - ETA: 4s - loss: 0.6893 - accuracy: 0.5430 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:49:45.436317: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-01-27 10:49:45.436333: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/42 [==>...........................] - ETA: 6s - loss: 0.6882 - accuracy: 0.5766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:49:45.917622: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-01-27 10:49:45.919043: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-01-27 10:49:45.922005: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45\n",
      "\n",
      "2022-01-27 10:49:45.923236: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45/AFYves-2.local.trace.json.gz\n",
      "2022-01-27 10:49:45.924816: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45\n",
      "\n",
      "2022-01-27 10:49:45.924969: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45/AFYves-2.local.memory_profile.json.gz\n",
      "2022-01-27 10:49:45.925478: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45\n",
      "Dumped tool data for xplane.pb to /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45/AFYves-2.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45/AFYves-2.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45/AFYves-2.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45/AFYves-2.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /Users/ycammarata/.keras/logs/model_use/train/plugins/profile/2022_01_27_10_49_45/AFYves-2.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.6908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:49:48.048450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 5s 98ms/step - loss: 0.6549 - accuracy: 0.6908 - val_loss: 0.5927 - val_accuracy: 0.7747\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.5469 - accuracy: 0.7711 - val_loss: 0.4851 - val_accuracy: 0.7909\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4775 - accuracy: 0.7848 - val_loss: 0.4534 - val_accuracy: 0.7970\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4600 - accuracy: 0.7955 - val_loss: 0.4453 - val_accuracy: 0.8080\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4582 - accuracy: 0.8041 - val_loss: 0.4431 - val_accuracy: 0.8115\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.4427 - accuracy: 0.8073 - val_loss: 0.4382 - val_accuracy: 0.8089\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.4346 - accuracy: 0.8098 - val_loss: 0.4363 - val_accuracy: 0.8110\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.4287 - accuracy: 0.8107 - val_loss: 0.4368 - val_accuracy: 0.8084\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4193 - accuracy: 0.8203 - val_loss: 0.4424 - val_accuracy: 0.8119\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4180 - accuracy: 0.8222 - val_loss: 0.4339 - val_accuracy: 0.8159\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "# We use here a sentence encoder named, Universal Sentence Encoder from tensorhub\n",
    "#################\n",
    "model_name = 'model_use'\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir_base+model_name)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['text_clean'], data['target'], test_size=0.3, random_state=42, stratify = data['target'])\n",
    "\n",
    "#create keras layer using the use layer from tensorflow hub\n",
    "MODEL_URL=\"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "sentence_encoder_layer=hub.KerasLayer(\n",
    "  MODEL_URL,\n",
    "  input_shape=[],\n",
    "  dtype=tf.string,\n",
    "  trainable=False,\n",
    "  name=\"USE\")\n",
    "\n",
    "#Create model using sequentinal api\n",
    "model_use=Sequential([\n",
    "  sentence_encoder_layer,\n",
    "  Dense(32,activation=\"relu\"),\n",
    "  Dense(16,activation=\"relu\"),\n",
    "  Dropout(0.4),\n",
    "  Dense(1,activation=\"sigmoid\",name=\"output_layer\"),\n",
    "  ],name=\"Model_USE\"\n",
    ")\n",
    "\n",
    "#Compile the model\n",
    "model_use.compile(\n",
    "  loss=\"binary_crossentropy\",\n",
    "  optimizer= 'adam',\n",
    "  metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "#trained the classfier on use layer\n",
    "model_history=model_use.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  epochs=10,\n",
    "  batch_size = 128,\n",
    "  validation_data=(X_val, y_val),\n",
    "  callbacks=[tensorboard_callback], \n",
    "  use_multiprocessing = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f953290869b00660eb2e8d887269ddf657efb8ebdbdd772af8ef2de03e9ecdc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
